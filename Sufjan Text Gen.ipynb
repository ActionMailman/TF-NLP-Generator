{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "strong-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "genetic-grain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
      "  GeForce GTX 1060, compute capability 6.1\n",
      "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
      "WARNING:tensorflow:From c:\\users\\orion\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\mixed_precision\\loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
     ]
    }
   ],
   "source": [
    "policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "continuous-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "data = open('compile.txt').read()\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "indonesian-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polar-circus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n",
      "Epoch 1/10\n",
      "1232/1232 [==============================] - 105s 77ms/step - loss: 6.5243 - accuracy: 0.0682\n",
      "Epoch 2/10\n",
      "1232/1232 [==============================] - 97s 79ms/step - loss: 4.5067 - accuracy: 0.2457\n",
      "Epoch 3/10\n",
      "1232/1232 [==============================] - 122s 99ms/step - loss: 3.3562 - accuracy: 0.3553\n",
      "Epoch 4/10\n",
      "1232/1232 [==============================] - 111s 90ms/step - loss: 2.6432 - accuracy: 0.4407\n",
      "Epoch 5/10\n",
      "1232/1232 [==============================] - 122s 99ms/step - loss: 2.2085 - accuracy: 0.5094\n",
      "Epoch 6/10\n",
      "1232/1232 [==============================] - 118s 96ms/step - loss: 1.9332 - accuracy: 0.5517\n",
      "Epoch 7/10\n",
      "1232/1232 [==============================] - 124s 100ms/step - loss: 1.8151 - accuracy: 0.5743\n",
      "Epoch 8/10\n",
      "1232/1232 [==============================] - 119s 96ms/step - loss: 1.6619 - accuracy: 0.6047\n",
      "Epoch 9/10\n",
      "1232/1232 [==============================] - 119s 97ms/step - loss: 1.6019 - accuracy: 0.6131\n",
      "Epoch 10/10\n",
      "1232/1232 [==============================] - 122s 99ms/step - loss: 1.5833 - accuracy: 0.6142\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000026BE4BFEE10>\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "adam = Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "history = model.fit(xs, ys, epochs=10, verbose=1)\n",
    "#print model.summary()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cloudy-insight",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\orion\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm very gay and very jesus please love me thank you but i'm not about to expect something more than you got me to be discovered love me in my heart and i feel just like more my own way i feel that empty outline changed my best i can feel the rhythm of your heart de vo tion x4 and have no shit wait the flood valentine spurn my brother's daughter i be invited to the world had it anyway sometimes it may not look just like me like a trumpet sound and i will touch of me i have no idea if i could put up on your plate\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"I'm very gay and very jesus please love me thank you\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
    "\toutput_word = \"\"\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == predicted:\n",
    "\t\t\toutput_word = word\n",
    "\t\t\tbreak\n",
    "\tseed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-disposition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
